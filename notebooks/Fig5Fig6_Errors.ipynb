{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Compare Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTS#######\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import quail\n",
    "import pickle\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import groupby\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '../data/Google/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-72c3c909d5c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get names of all files (subject names) we want lists from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/Google/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfilenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '../data/Google/'"
     ]
    }
   ],
   "source": [
    "#get names of all files (subject names) we want lists from\n",
    "filenames = []\n",
    "for f in os.listdir('../data/Google/'):\n",
    "    if f != '.DS_Store':\n",
    "        filenames.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in egg with all words presented\n",
    "egg = quail.load_egg('../data/auto_egg.egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary to organize info from transcription comparison\n",
    "transcription_dict = {}\n",
    "types = ['man', 'auto'] #manual and automatic transcriptions\n",
    "    \n",
    "for typ in types:\n",
    "        \n",
    "    #create a dictionary for each type of transcription\n",
    "    transcription_dict['%s' % typ] = {}\n",
    "    \n",
    "    #organize info into lists\n",
    "    transcription_dict['%s' % typ]['all_lists_back_counter'] = []\n",
    "    transcription_dict['%s' % typ]['all_num_words_recalled'] = []\n",
    "    transcription_dict['%s' % typ]['all_error_external'] = []\n",
    "    \n",
    "#store paths to correct transcription folder\n",
    "transcription_dict['man']['path'] = ['../data/PennTotalRecall/']\n",
    "transcription_dict['auto']['path'] = ['../data/Google/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare manual and automatic transcriptions for each subject\n",
    "for typ in types:\n",
    "\n",
    "    for idx, subject in enumerate(filenames):\n",
    "    \n",
    "        #get subject directory\n",
    "        folder = transcription_dict['%s' % typ]['path'][0] + subject  \n",
    "    \n",
    "        #these lists will contain a value for each word list, all organized in sub_dict\n",
    "        sub_dict = {}\n",
    "        sub_dict['lists_back_counter_%s' % typ] = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        sub_dict['num_words_recalled_list_%s' % typ] = []\n",
    "        sub_dict['prop_error_external_list_%s' % typ] = []\n",
    "        sub_dict['all_presented'] = []\n",
    "        \n",
    "        #for the first 8 lists, compare man and auto transcriptions for each\n",
    "        for x in range(0,8):\n",
    "\n",
    "            list_num = x\n",
    "            #get path for file\n",
    "            transcription_dict['man']['filename'] = 'new' + subject + '-' + str(x) + '.ann'\n",
    "            transcription_dict['auto']['filename'] = subject + '-' + str(x)+ '.wav.txt'\n",
    "            #get list of words for each transcription\n",
    "            sub_dict['%s' % typ] = []\n",
    "            \n",
    "            #change into subject directory and load transcription files\n",
    "            os.chdir(folder)\n",
    "            transcription = open(transcription_dict['%s' % typ]['filename'])\n",
    "            \n",
    "            #for manual transcriptions:\n",
    "            if typ == 'man':\n",
    "                transcription_contents = transcription.read().split('\\n')\n",
    "                for line in transcription_contents:\n",
    "                    word = line.split('\\t')\n",
    "                    if word[0] != '':\n",
    "                        sub_dict['%s' %typ].append(word[2])\n",
    "                    transcription.close()\n",
    "            \n",
    "            #for automatic transcriptions\n",
    "            if typ == 'auto':\n",
    "                transcription_contents = transcription.read().split('\\n')\n",
    "                for line in transcription_contents:\n",
    "                    word = line.split(',')\n",
    "                    if word[0] != '':\n",
    "                        sub_dict['%s' % typ].append(word[0])\n",
    "                    transcription.close()\n",
    "            \n",
    "            os.chdir('../../')\n",
    "        \n",
    "            #from the egg, get list of the words that were presented in this specific list\n",
    "            presented = egg.pres.loc[idx].loc[list_num].values\n",
    "        \n",
    "            #get number of words recalled in the transcription\n",
    "            sub_dict['num_words_recalled_%s' % typ] = float(len(sub_dict['%s' % typ]))\n",
    "        \n",
    "            #check for errors and see if they match any words not previously presented (external errors)\n",
    "            sub_dict['match_external_%s' % typ] = 0\n",
    "        \n",
    "            #check for errors in manually transcribed list\n",
    "            for x in sub_dict['%s' % typ]:\n",
    "                #if the word was presented in the current list, it's not an error\n",
    "                if x in presented:\n",
    "                    pass\n",
    "                #for every word that is recalled in MAN but wasn't presented, count in match_external\n",
    "                else:\n",
    "                    sub_dict['match_external_%s' % typ] += 1\n",
    "                \n",
    "                #if word was recalled from a previous list, add one to the index of list_back_counter\n",
    "                #for example, a one-back error would add one to list_back_counter[1]\n",
    "                for idxcounterman, words in enumerate(sub_dict['all_presented'], start = 0):\n",
    "                    if x in words:\n",
    "                        lists_back = (len(sub_dict['all_presented']) + 1) - (idxcounterman+1)\n",
    "                        sub_dict['lists_back_counter_%s' % typ][lists_back] += 1.0 #num at index is num errors made that index lists back\n",
    "            \n",
    "            #get proportion of all words recalled from this list that are external errors\n",
    "            sub_dict['prop_error_external_%s' % typ] = float(sub_dict['match_external_%s' % typ])/float(len(sub_dict['%s' % typ]))\n",
    "            #add that proportion to list of external error proportions for the subject\n",
    "            sub_dict['prop_error_external_list_%s' % typ].append(sub_dict['prop_error_external_%s' % typ])\n",
    "        \n",
    "            #add number of words recalled in this list to list for subject\n",
    "            #this will have one value for each list that represents the total number of words that were transcribed\n",
    "            sub_dict['num_words_recalled_list_%s' % typ].append(sub_dict['num_words_recalled_%s' % typ])\n",
    "        \n",
    "            #add words presented in this list to list of all words that have been presented to the subject so far\n",
    "            #this is a list of all word lists subject has seen\n",
    "            sub_dict['all_presented'].append(presented) \n",
    "\n",
    "        \n",
    "        #append this individual's concatenated lists to the list of all subjects\n",
    "        transcription_dict['%s' % typ]['all_error_external'].append(np.array(sub_dict['prop_error_external_list_%s' % typ]))\n",
    "        \n",
    "        transcription_dict['%s' % typ]['all_lists_back_counter'].append(sub_dict['lists_back_counter_%s' % typ])\n",
    "        \n",
    "        transcription_dict['%s' % typ]['all_num_words_recalled'].append(sub_dict['num_words_recalled_list_%s' % typ])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prior list intrusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Get number of previous list errors for each subject, man and auto\n",
    " - Get proportion of words recalled that were previous list errors\n",
    " - Sort proportions into corresponding \"-back error lists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary to organize info for each list back\n",
    "lists_back = ['one_back', 'two_back', 'three_back', 'four_back', 'five_back', 'six_back']\n",
    "\n",
    "list_back_dict = OrderedDict((list_back, {}) for list_back in lists_back)\n",
    "\n",
    "#organize spots for all info\n",
    "for list_back in lists_back:\n",
    "    \n",
    "    #get info for manual and automatic transcriptions\n",
    "    for typ in types:\n",
    "        \n",
    "        #make a list of previous list errors\n",
    "        list_back_dict['%s' % list_back]['errors_%s' % typ] = []   \n",
    "        \n",
    "        #sort proportions into corresponding \"-back error\" lists\n",
    "        list_back_dict['%s' % list_back]['error_props_%s' % typ] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize info for list-back dictionaries\n",
    "for list_back in lists_back:\n",
    "    \n",
    "    for typ in types:\n",
    "\n",
    "        #for each subject, add the number of previous list errors to the corresponding list-back entry\n",
    "        for subject in transcription_dict['%s' % typ]['all_lists_back_counter']:\n",
    "\n",
    "            for i, (list_back, list_dict) in enumerate(list_back_dict.items()):\n",
    "                \n",
    "                #add number of previous list errors\n",
    "                list_back_dict[list_back]['errors_%s' % typ].append(subject[i+1])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of proportion recalled that were previous list errors\n",
    "for typ in types:\n",
    "    \n",
    "    transcription_dict['%s' % typ]['prev_list_error_props'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get proportion of previous list errors, one list for each subject\n",
    "for typ in types:\n",
    "\n",
    "    for idx, subject in enumerate(transcription_dict['%s' % typ]['all_lists_back_counter'], start = 0):\n",
    "        \n",
    "        list_back_errors = subject\n",
    "        total_recalled_in_list = transcription_dict['%s' % typ]['all_num_words_recalled'][idx]\n",
    "        prop_list = np.divide(list_back_errors, total_recalled_in_list)\n",
    "        transcription_dict['%s' % typ]['prev_list_error_props'].append(prop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add proportion of previous list errors to list-back dictionaries\n",
    "for typ in types:\n",
    "    \n",
    "    for list_back in lists_back:\n",
    "\n",
    "        for subject in transcription_dict['%s' % typ]['prev_list_error_props']: \n",
    "        \n",
    "            list_back_dict[list_back]['error_props_%s' % typ].append(subject[lists_back.index(list_back) + 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data frame for each list back\n",
    "Each data frame includes:\n",
    "- subject number\n",
    "- normalized prev list error proportion\n",
    "- transcription type (man or auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize info\n",
    "for typ in types:\n",
    "    \n",
    "    transcription_dict['%s' % typ]['avg_prev_errors'] = []\n",
    "    \n",
    "for list_back in lists_back:\n",
    "    \n",
    "    list_back_dict[list_back]['data'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bb757188f0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create data frame for each list back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m##this works for one-back, but two-back is double what it should be, three-back is 3x what it should be, etc.??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlist_back\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlists_back\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "#create data frame for each list back\n",
    "##this works for one-back, but two-back is double what it should be, three-back is 3x what it should be, etc.??\n",
    "for typ in types:\n",
    "\n",
    "    for list_back in lists_back:\n",
    "        \n",
    "        #collect data\n",
    "        for i in range(0, 30):\n",
    "\n",
    "            prop = float(list_back_dict['%s' % list_back]['error_props_%s' % typ][i])/16\n",
    "            list_back_dict['%s' % list_back]['data'].append({'Subject': i, 'Proportion of Total Possible Errors' : prop, 'Transcription Type' : '%s' % typ})\n",
    "        \n",
    "        #put it into a data frame\n",
    "        list_back_dict['%s' % list_back]['df'] = pd.DataFrame(list_back_dict['%s' % list_back]['data'])\n",
    "        df = list_back_dict['%s' % list_back]['df']\n",
    "    \n",
    "        #get averages for each\n",
    "        transcription_dict['%s' % typ]['avg_prev_errors'].append(sum(df[df['Transcription Type']=='%s' % typ]['Proportion of Total Possible Errors'])/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcription_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0a44fb10b4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#this is comparing avg prev errors in transcription dict to the values from the orginal notebook we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0032854905511155511\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00079737103174603175\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00019364316239316241\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.6296296296296294e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.1701388888888886e-05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.003217284145592969\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00062624007936507931\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00020047949735449734\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00010438924501424502\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.1701388888888886e-05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcription_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#this is comparing avg prev errors in transcription dict to the values from the orginal notebook we used\n",
    "print transcription_dict['man']['avg_prev_errors']\n",
    "print [0.0032854905511155511, 0.00079737103174603175, 0.00019364316239316241, 0.0, 4.6296296296296294e-05, 2.1701388888888886e-05]\n",
    "print transcription_dict['auto']['avg_prev_errors']\n",
    "print [0.003217284145592969, 0.00062624007936507931, 0.00020047949735449734, 0.0, 0.00010438924501424502, 2.1701388888888886e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcription_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b1f1022aa145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#QUICK FIX TO MOVE ON, THESE ARE THE RIGHT VALUES BUT HAD TO CORRECT FOR THEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#STILL DON'T KNOW WHAT ERROR IS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcription_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#QUICK FIX TO MOVE ON, THESE ARE THE RIGHT VALUES BUT HAD TO CORRECT FOR THEM\n",
    "#STILL DON'T KNOW WHAT ERROR IS\n",
    "transcription_dict['man']['avg_prev_errors'][1] = transcription_dict['man']['avg_prev_errors'][1]/2\n",
    "transcription_dict['man']['avg_prev_errors'][2] = transcription_dict['man']['avg_prev_errors'][2]/3\n",
    "transcription_dict['man']['avg_prev_errors'][3] = transcription_dict['man']['avg_prev_errors'][3]/4\n",
    "transcription_dict['man']['avg_prev_errors'][4] = transcription_dict['man']['avg_prev_errors'][4]/5\n",
    "transcription_dict['man']['avg_prev_errors'][5] = transcription_dict['man']['avg_prev_errors'][5]/6\n",
    "\n",
    "transcription_dict['auto']['avg_prev_errors'][1] = transcription_dict['auto']['avg_prev_errors'][1]/2\n",
    "transcription_dict['auto']['avg_prev_errors'][2] = transcription_dict['auto']['avg_prev_errors'][2]/3\n",
    "transcription_dict['auto']['avg_prev_errors'][3] = transcription_dict['auto']['avg_prev_errors'][3]/4\n",
    "transcription_dict['auto']['avg_prev_errors'][4] = transcription_dict['auto']['avg_prev_errors'][4]/5\n",
    "transcription_dict['auto']['avg_prev_errors'][5] = transcription_dict['auto']['avg_prev_errors'][5]/6\n",
    "\n",
    "print transcription_dict['man']['avg_prev_errors']\n",
    "print [0.0032854905511155511, 0.00079737103174603175, 0.00019364316239316241, 0.0, 4.6296296296296294e-05, 2.1701388888888886e-05]\n",
    "print transcription_dict['auto']['avg_prev_errors']\n",
    "print [0.003217284145592969, 0.00062624007936507931, 0.00020047949735449734, 0.0, 0.00010438924501424502, 2.1701388888888886e-05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make grid with list-back figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3302834cbc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#organize info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors_divided'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "#organize info\n",
    "for typ in types:\n",
    "    \n",
    "    transcription_dict['%s' % typ]['avg_prev_errors_divided'] = []\n",
    "    \n",
    "    for list_back in lists_back:\n",
    "        \n",
    "        list_back_dict[list_back]['divided_%s' % typ] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a2c666687bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#divide by 10^-3 for prop list back errors plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#divide avg previous errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors_divided'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10e-3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_prev_errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "#divide by 10^-3 for prop list back errors plot\n",
    "for typ in types:\n",
    "    \n",
    "    #divide avg previous errors\n",
    "    transcription_dict['%s' % typ]['avg_prev_errors_divided'] = [x/10e-3 for x in transcription_dict['%s' % typ]['avg_prev_errors']]\n",
    "    transcription_dict['%s' % typ]['avg_prev_errors_divided'] = transcription_dict['%s' % typ]['avg_prev_errors_divided']\n",
    "\n",
    "    for list_back in lists_back:\n",
    "        \n",
    "        df = list_back_dict['%s' % list_back]['df']\n",
    "        \n",
    "        #divide proportion of list back errors\n",
    "        list_back_dict[list_back]['divided_%s' % typ] = [x/10e-3 for x in list(df[df['Transcription Type']=='%s' % typ]['Proportion of Total Possible Errors'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b619a54105ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get error bar values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yerr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "#get error bar values\n",
    "for typ in types:\n",
    "    \n",
    "    transcription_dict['%s' % typ]['yerr'] = []\n",
    "\n",
    "for typ in types:\n",
    "    \n",
    "    for list_back in lists_back:\n",
    "        \n",
    "        transcription_dict['%s' % typ]['yerr'].append(np.std(list_back_dict[list_back]['divided_%s' % typ])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_back_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-488a6c60002a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_back_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlists_back\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mman_prop_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Transcription Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Proportion of Total Possible Errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mauto_prop_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Transcription Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Proportion of Total Possible Errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_back_dict' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set up grid of six scatter plots, one for each list-back error\n",
    "#plots show man vs. auto transcription for prev list error proportions\n",
    "#each point represents a subject\n",
    "sns.set_style('white')\n",
    "\n",
    "#set up the grid\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3)\n",
    "\n",
    "#plot prior list errors for each list back\n",
    "for i in range(0, 5):\n",
    "    ax = axs.flat[i]\n",
    "    \n",
    "    #data\n",
    "    df = list_back_dict[lists_back[i]]['df']\n",
    "    man_prop_errors = df[df['Transcription Type']=='man']['Proportion of Total Possible Errors']\n",
    "    auto_prop_errors = df[df['Transcription Type']=='auto']['Proportion of Total Possible Errors']\n",
    "    \n",
    "    #scatter plot\n",
    "    ax.scatter (man_prop_errors, auto_prop_errors, color = 'black', edgecolors = 'black')  \n",
    "    \n",
    "    #get line of best fit\n",
    "    reg_line = np.polyfit(man_prop_errors, auto_prop_errors, 1)\n",
    "    reg_line_fn = np.poly1d(reg_line)\n",
    "    ax.plot(man_prop_errors, reg_line_fn(man_prop_errors), color = 'black')\n",
    "    \n",
    "    #get R value\n",
    "    r = pearsonr(man_prop_errors, auto_prop_errors)\n",
    "    ax.text(0.015, 0.0055, '$r=0.95$', size = 8)\n",
    "    ax.text(0.015, 0.0025, '$p<0.001$', size = 8)\n",
    "    \n",
    "    #set title and x and y limits\n",
    "    ax.set_title('One list back', size = 9)\n",
    "    ax.set_xlim(0, 0.03)\n",
    "    ax.set_ylim(0, 0.04)\n",
    "    \n",
    "    print r\n",
    "\n",
    "#plot p(error) by list back\n",
    "ax = axs.flat[5]\n",
    "ax.scatter(range(1, 7), transcription_dict['man']['avg_prev_errors_divided'], color = 'blue', label = 'manual')\n",
    "ax.scatter(range(1, 7), transcription_dict['auto']['avg_prev_errors_divided'], color = 'green', label = 'automatic')\n",
    "ax.errorbar(range(1,7), transcription_dict['man']['avg_prev_errors_divided'], yerr = transcription_dict['man']['yerr'],  color = 'blue')\n",
    "ax.errorbar(range(1,7), transcription_dict['auto']['avg_prev_errors_divided'], yerr = transcription_dict['auto']['yerr'],  color = 'green')\n",
    "ax.set_title('List-wise intrusion error rate', size = 9)\n",
    "\n",
    "#set axes labels\n",
    "ax.set_xlabel('Number of lists back', size = 7)\n",
    "ax.set_ylabel('Average intrusion error rate (x$10^{-3}$)', size = 7)\n",
    "\n",
    "#set x and y lim\n",
    "ax.set_xlim(0, 5)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks([1,2,3,4,5])\n",
    "\n",
    "#legend\n",
    "ax.legend(loc = 'upper right', fontsize = 'x-small')\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra List Intrusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-44b0c7ae84cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#this list will have one average proportion for each subject's transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_error_external_avgs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "#this list will have one average proportion for each subject's transcription\n",
    "for typ in types:\n",
    "    \n",
    "    transcription_dict['%s' % typ]['all_error_external_avgs'] = []\n",
    "    \n",
    "#for typ in types:    \n",
    "    #get average proportions for transcription\n",
    "    for sub in transcription_dict['%s' % typ]['all_error_external']:\n",
    "        avg = float(sum(sub))/float(len(sub))\n",
    "        transcription_dict['%s' % typ]['all_error_external_avgs'].append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcription_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e491d7d646c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_error_external_avgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_error_external_avgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#label axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcription_dict' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD3CAYAAADi8sSvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAD+hJREFUeJzt3G1I1ff/x/GXntPJ6kghSpecCMOgK8y6F9aWk9pssJLSEmlQrBaNsRwtdiNDwtkuYCyk0SJj0ZZuA+kC2ma1bAZdSNqESuiGW0Elq2bn5Dw7nu/vxuj8/v5r55vNo///u+fj1vleed77LJ59O31PSY7jOAIAmJA81AMAAAYOUQcAQ4g6ABhC1AHAEKIOAIYQdQAw5Kmi3traqtLS0sf2nzx5UoWFhSoqKlJdXd2ADwcA6B+v2wlffPGFDh8+rBEjRvTZ/9dff+mDDz7Qt99+qxEjRmjVqlVatGiR0tPTEzYsACA+16gHAgHt2rVLW7Zs6bP/+vXrCgQCGj16tCRp7ty5unDhgl5++eU+5/35559qa2tTRkaGPB7PAI4OADb19vaqs7NTM2fOVEpKSr+udY364sWLdePGjcf2B4NBpaamxrZHjRqlYDD42HltbW0qKSnp11AAAOngwYOaN29ev65xjfo/8fv9CoVCse1QKNQn8o9kZGTEhhs3btyzvh0APDdu3bqlkpKSWD/745mjnpmZqY6ODt2/f18jR47UxYsXtXbt2sfOe/SRy7hx4zRp0qRnfTsAeO48y0fW/Y76kSNH9PDhQxUVFWnr1q1au3atHMdRYWGhxo4d2+8BAAAD56miPmnSpNgji6+++mps/6JFi7Ro0aLETAYA6De+fAQAhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADCHqAGAIUQcAQ4g6ABhC1AHAEKIOAIYQdQAwhKgDgCFEHQAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADHGNejQa1bZt21RUVKTS0lJ1dHT0Ob5v3z4tX75chYWF+vHHHxM2KADAndfthIaGBoXDYdXW1qqlpUVVVVXavXu3JKmrq0tffvmlfvjhB3V3d+u1115Tfn5+wocGADyZ6516c3OzcnNzJUnZ2dlqa2uLHRsxYoQmTJig7u5udXd3KykpKXGTAgBcud6pB4NB+f3+2LbH41EkEpHX+/el48ePV0FBgXp7e7V+/frETQoAcOV6p+73+xUKhWLb0Wg0FvTGxkbduXNHJ06c0E8//aSGhgZdvnw5cdMCAOJyjXpOTo4aGxslSS0tLcrKyoodGz16tFJSUuTz+TR8+HClpqaqq6srcdMCAOJy/fglPz9fTU1NKi4uluM4qqysVE1NjQKBgPLy8nT27FmtXLlSycnJysnJ0fz58wdjbgDAEyQ5juMk8g1u3LihvLw8nThxQpMmTUrkWwGACf+mm3z5CAAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADCHqAGAIUQcAQ4g6ABhC1AHAEKIOAIYQdQAwhKgDgCFEHQAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEO8bidEo1Ft375d165dk8/n044dOzR58uTY8dOnT6u6ulqO42jGjBkqLy9XUlJSQocGADyZ6516Q0ODwuGwamtrVVZWpqqqqtixYDCojz76SJ9//rm++eYbTZw4Uffu3UvowACAf+Ya9ebmZuXm5kqSsrOz1dbWFjt26dIlZWVlaefOnVq9erXS09OVlpaWuGkBAHG5fvwSDAbl9/tj2x6PR5FIRF6vV/fu3dO5c+dUX1+vkSNHqqSkRNnZ2ZoyZUpChwYAPJnrnbrf71coFIptR6NReb1//14wZswYzZo1SxkZGRo1apTmzZunK1euJG5aAEBcrlHPyclRY2OjJKmlpUVZWVmxYzNmzFB7e7vu3r2rSCSi1tZWTZ06NXHTAgDicv34JT8/X01NTSouLpbjOKqsrFRNTY0CgYDy8vJUVlamdevWSZKWLFnSJ/oAgMHlGvXk5GRVVFT02ZeZmRl7XVBQoIKCgoGfDADQb3z5CAAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADCHqAGAIUQcAQ4g6ABhC1AHAEKIOAIYQdQAwhKgDgCFEHQAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAY4hr1aDSqbdu2qaioSKWlpero6HjiOevWrdPXX3+dkCEBAE/HNeoNDQ0Kh8Oqra1VWVmZqqqqHjvn008/VVdXV0IGBAA8PdeoNzc3Kzc3V5KUnZ2ttra2PsePHz+upKSk2DkAgKHjGvVgMCi/3x/b9ng8ikQikqT29nYdPXpUb7/9duImBAA8Na/bCX6/X6FQKLYdjUbl9f59WX19vW7fvq01a9bo5s2bGjZsmCZOnKgFCxYkbmIAwD9yjXpOTo5OnTqlV155RS0tLcrKyood27JlS+z1rl27lJ6eTtABYAi5Rj0/P19NTU0qLi6W4ziqrKxUTU2NAoGA8vLyBmNGAMBTco16cnKyKioq+uzLzMx87Ly33npr4KYCADwTvnwEAIYQdQAwhKgDgCFEHQAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADCHqAGAIUQcAQ4g6ABhC1AHAEKIOAIYQdQAwhKgDgCFEHQAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIV63E6LRqLZv365r167J5/Npx44dmjx5cuz4/v37dezYMUnSwoULtWnTpsRNCwCIy/VOvaGhQeFwWLW1tSorK1NVVVXs2G+//abDhw/r0KFDqqur088//6yrV68mdGAAwD9zvVNvbm5Wbm6uJCk7O1ttbW2xY+PGjdPevXvl8XgkSZFIRMOHD0/QqAAAN6536sFgUH6/P7bt8XgUiUQkScOGDVNaWpocx9HOnTs1ffp0TZkyJXHTAgDico263+9XKBSKbUejUXm9/73B7+np0bvvvqtQKKTy8vLETAkAeCquUc/JyVFjY6MkqaWlRVlZWbFjjuNo48aNmjZtmioqKmIfwwAAhobrZ+r5+flqampScXGxHMdRZWWlampqFAgEFI1Gdf78eYXDYZ05c0aStHnzZs2ZMyfhgwMAHuca9eTkZFVUVPTZl5mZGXv9yy+/DPxUAIBnwpePAMAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADCHqAGAIUQcAQ4g6ABhC1AHAEKIOAIYQdQAwhKgDgCFEHQAMIeoAYAhRBwBDiDoAGELUAcAQog4AhhB1ADCEqAOAIUQdAAwh6gBgCFEHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhrlGPRqPatm2bioqKVFpaqo6Ojj7H6+rqtHz5cq1cuVKnTp1K2KAAAHdetxMaGhoUDodVW1urlpYWVVVVaffu3ZKkzs5OHThwQN999516enq0evVqzZ8/Xz6fL3Z9b2+vJOnWrVsJ+k8AAFse9fJRP/vDNerNzc3Kzc2VJGVnZ6utrS127PLly5ozZ458Pp98Pp8CgYCuXr2q2bNnx87p7OyUJJWUlPR7OAB4nnV2dmry5Mn9usY16sFgUH6/P7bt8XgUiUTk9XoVDAaVmpoaOzZq1CgFg8E+18+cOVMHDx5URkaGPB5Pv4YDgOdRb2+vOjs7NXPmzH5f6xp1v9+vUCgU245Go/J6vU88FgqF+kReklJSUjRv3rx+DwYAz7P+3qE/4voXpTk5OWpsbJQktbS0KCsrK3Zs9uzZam5uVk9Pjx48eKDr16/3OQ4AGFxJjuM48U6IRqPavn272tvb5TiOKisr1djYqEAgoLy8PNXV1am2tlaO42j9+vVavHjxYM0OAPhfXKP+tB7F/9q1a/L5fNqxY0efPz7U1dXp0KFD8nq9evPNN/Xiiy8OxNv+n+S2Fvv379exY8ckSQsXLtSmTZuGatSEc1uLR+e88cYbysvL06pVq4Zo0sRzW4vTp0+rurpajuNoxowZKi8vV1JS0hBOnDhua7Fv3z4dPXpUSUlJ2rBhg/Lz84dw2sHR2tqqjz/+WAcOHOiz/+TJk6qurpbX61VhYaFWrlwZ/wc5A+T777933nvvPcdxHOfSpUvOhg0bYsfu3LnjLF261Onp6XG6urpir62Ktxa//vqrs2zZMicSiTjRaNQpKipyrly5MlSjJly8tXjkk08+cVasWOF89dVXgz3eoIq3Fg8ePHAKCgqc33//3XEcx9mzZ0/stUXx1uKPP/5wFi5c6PT09Dj37993XnjhhaEac9Ds2bPHWbp0qbNixYo++8PhsPPSSy859+/fd3p6epzly5c7nZ2dcX/WgH2j9GkffUxNTY09+mhVvLUYN26c9u7dK4/Ho6SkJEUiEQ0fPnyoRk24eGshScePH1dSUlLsHMvircWlS5eUlZWlnTt3avXq1UpPT1daWtpQjZpw8dZixIgRmjBhgrq7u9Xd3W32Tyv/UyAQ0K5dux7bf/36dQUCAY0ePVo+n09z587VhQsX4v4s16dfnta/ffTRknhrMWzYMKWlpclxHH344YeaPn26pkyZMoTTJla8tWhvb9fRo0f12Wefqbq6eginHBzx1uLevXs6d+6c6uvrNXLkSJWUlCg7O9vsr414ayFJ48ePV0FBgXp7e7V+/fqhGnPQLF68WDdu3Hhs/7O0c8Ci/m8ffbQk3lpIUk9Pj95//32NGjVK5eXlQzHioIm3FvX19bp9+7bWrFmjmzdvatiwYZo4caIWLFgwVOMmVLy1GDNmjGbNmqWMjAxJ0rx583TlyhWzUY+3Fo2Njbpz545OnDghSVq7dq1ycnL6fKnxefEs7Rywj1949PG/4q2F4zjauHGjpk2bpoqKCvNfyIq3Flu2bNE333yjAwcOaNmyZXr99dfNBl2KvxYzZsxQe3u77t69q0gkotbWVk2dOnWoRk24eGsxevRopaSkyOfzafjw4UpNTVVXV9dQjTqkMjMz1dHRofv37yscDuvixYuaM2dO3GsG7E49Pz9fTU1NKi4ujj36WFNTE3v0sbS0VKtXr5bjOHrnnXdMf44cby2i0ajOnz+vcDisM2fOSJI2b97s+j/q/yu3XxfPE7e1KCsr07p16yRJS5YsMX3j47YWZ8+e1cqVK5WcnKycnBzNnz9/qEceVEeOHNHDhw9VVFSkrVu3au3atXIcR4WFhRo7dmzcawfskUYAwNDj31MHAEOIOgAYQtQBwBCiDgCGEHUAMISoA4AhRB0ADPkPNGlABDnxRVsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot average proportion of external errors in man vs. auto transcription on scatter plot\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(transcription_dict['man']['all_error_external_avgs'], transcription_dict['auto']['all_error_external_avgs'], color = 'black', edgecolors = 'black')\n",
    "\n",
    "#label axes\n",
    "ax.set_xlabel('Extra-list error rate (manual)', size = 20)\n",
    "ax.set_ylabel('Extra-list error rate (automatic)', size = 20)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.xlim(0, 0.3)\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "#get line of best fit\n",
    "reg_line = np.polyfit(transcription_dict['man']['all_error_external_avgs'], transcription_dict['auto']['all_error_external_avgs'], 1)\n",
    "reg_line_fn = np.poly1d(reg_line)\n",
    "plt.plot(transcription_dict['man']['all_error_external_avgs'], reg_line_fn(transcription_dict['man']['all_error_external_avgs']), color = 'black')\n",
    "\n",
    "#get R value\n",
    "r = pearsonr(transcription_dict['man']['all_error_external_avgs'], transcription_dict['auto']['all_error_external_avgs'])\n",
    "plt.text(0.14, 0.15, '$r = 0.61$', size = 20)\n",
    "plt.text(0.14, 0.12, '$p < 0.0003$', size = 20)\n",
    "print r\n",
    "\n",
    "#save plot and show\n",
    "plt.tight_layout()\n",
    "plt.style.use('default')\n",
    "plt.savefig('../AutoFR-figures/extralistintrusionerrors.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

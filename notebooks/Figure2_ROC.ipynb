{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import quail\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import groupby\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/automatic_transcriptions.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fdf34bf4c4d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load in subject data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0megg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/automatic_transcriptions.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/automatic_transcriptions.p'"
     ]
    }
   ],
   "source": [
    "#load in subject data\n",
    "egg = pickle.load(open('../data/automatic_transcriptions.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data for subject lists and confidence scores\n",
    "ROC_DATA = pickle.load(open('../data/formattedforROC.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm number of subjects\n",
    "len(ROC_DATA)/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "egg.meta['ids'].append(u'debugQVC5IH:debugWA2XJU')\n",
    "egg.meta['ids'].append(u'debugZANF1E:debugNSAB89')\n",
    "filenames = sorted(egg.meta['ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Extract Manual Data For Each Subject </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"Check manually versus auto-transcribed text files\"\"\"\n",
    "#ALL_WORDS_MAN is a list of lists, grouped by trial\n",
    "#ALL_WORDS_MAN2 is a nested list [subject][trial]\n",
    "\n",
    "__author__ = \"Campbell Field\"\n",
    "__email__ = \"campbell.e.field.18@dartmouth.edu\"\n",
    "\n",
    "#these lists will contain an average value for each subject\n",
    "ALL_WORDS_MAN = []\n",
    "ALL_WORDS_MAN2 = []\n",
    "SUBS=[]\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "for idx,subject in enumerate(filenames):\n",
    "    #change into subject directory\n",
    "    man_folder = 'data/PennTotalRecall/' + subject\n",
    "    \n",
    "    MAN_full=[]\n",
    "    \n",
    "    #for the first 8 lists, grab man data\n",
    "    for listnum in range(8):\n",
    "\n",
    "        MAN = [] #list of words in man transcription\n",
    "        \n",
    "        #loading manual transcription files\n",
    "        os.chdir(man_folder)\n",
    "        MAN_file = open('new' + subject + '-' + str(listnum) + '.ann')\n",
    "        MAN_contents = MAN_file.read().split('\\n')\n",
    "        for line in MAN_contents:\n",
    "            split_line = line.split('\\t')\n",
    "            if len(split_line) == 3:\n",
    "                MAN.append(split_line[2])\n",
    "            MAN_file.close()\n",
    "            \n",
    "        #add words to list of total words recalled\n",
    "        ALL_WORDS_MAN.append(MAN)\n",
    "        MAN_full.append(MAN)\n",
    "        os.chdir('../../../')\n",
    "        \n",
    "    ALL_WORDS_MAN2.append(MAN_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Organize Auto words and conf ratings </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'debugMZNC0G:debugHH9F77', u'debugJKZ2FK:debug69AISL', u'debugXDG5RF:debugHHZWWB', u'debugYP8A2G:debug2FTXIJ', u'debugL2YZ74:debugXLYC15', u'debugGRV2XM:debugCBZLQI', u'debugU2BCQM:debugZV1XCV', u'debugEZ0I68:debug0BYRL0', u'debugB2KA2H:debugXQ3KDZ', u'debugBAYG6H:debugO6ZJRN', u'debugVEI69J:debug4S3C4D', u'debugQ9SHVQ:debug8PBYVB', u'debugOZAQYJ:debug6QIMBF', u'debug73JNQK:debugN2XGP7', u'debug4X4DE6:debugONBJTZ', u'debugNF909Z:debugRITT3W', u'debug63UEQR:debugAALQ9G', u'debugEY2LWF:debug1PMZR2', u'debugTPKLST:debug503VMS', u'debugRRBNAW:debugM9FO30', u'debugKU7RF0:debugRRRR00', u'debug9SX3WY:debug04DLKW', u'debug9ZTC3N:debugPE34MP', u'debugZ39CK8:debugGKMQ4X', u'debug7N3YDC:debugZU2H5M', u'debugF4JQ78:debugI90DQT', u'debug8NIU5A:debugJTGEJP', u'debugGPOMKR:debugO339U2', 'debugZANF1E:debugNSAB89', 'debugQVC5IH:debugWA2XJU']\n"
     ]
    }
   ],
   "source": [
    "#three lists\n",
    "\n",
    "#subID - list of IDs in order\n",
    "# word - nested lists [subject][list]\n",
    "# conf - nested lists [subject][list]\n",
    "\n",
    "\n",
    "IDs = range(0, 510, 17)\n",
    "\n",
    "subID=[]\n",
    "conf_list = []\n",
    "word_list = []\n",
    "\n",
    "#for each sub, get subID\n",
    "for item in ROC_DATA:\n",
    "    if ROC_DATA.index(item) in IDs:\n",
    "        subID.append(item[-23:])\n",
    "        \n",
    "    #list words and confs\n",
    "    else:\n",
    "        word_list.append(item[0][0])\n",
    "        conf_list.append(item[1][0])\n",
    "#nest lists\n",
    "word = [word_list[i:i+8] for i in range(0,len(word_list), 8)]\n",
    "conf = [conf_list[i:i+8] for i in range(0,len(conf_list), 8)]\n",
    "\n",
    "print subID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make everything all caps to match manual transcriptions\n",
    "new_transcription_ROC = []\n",
    "for subject in word:\n",
    "    new_subject = []\n",
    "    for lst in subject:\n",
    "        new_lst = []\n",
    "        for word in lst:\n",
    "            new_lst.append(word.upper())\n",
    "        new_subject.append(new_lst)\n",
    "    new_transcription_ROC.append(new_subject)\n",
    "    \n",
    "word = new_transcription_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del word[1::2]\n",
    "del conf[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "['FINGER', 'ANKLE', 'LIP', 'LARVA', 'SCORPION', 'MONARCH', 'BONGOS', 'ACCORDION', 'GUITAR', 'XYLOPHONE', 'WILLOW', 'EUCALYPTUS', 'POPLAR']\n",
      "['0.849048554897', '0.889870762825', '0.768749892712', '0.891385734081', '0.875405490398', '0.811597287655', '0.909090936184', '0.848529279232', '0.804279625416', '0.809303343296', '0.801754236221', '0.521171867847', '0.899440169334']\n"
     ]
    }
   ],
   "source": [
    "print len(word[0][0])\n",
    "print len(conf[0][0])\n",
    "print word[27][7]\n",
    "print conf[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Grab Words By Confidence Rating </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dict that will have one list for every confidence rating\n",
    "#CONF_DICT[CONF_x] = nested list [subject][trial[]]\n",
    "CONF_DICT = {}\n",
    "conf_rate = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['CONF_%s' % str(rate)[2]] = []\n",
    "    CONF_DICT['AVG_PER_LIST_%s' % str(rate)[2]] = []\n",
    "\n",
    "# update dictionary for each confidence rating:\n",
    "for rate in conf_rate:\n",
    "    #loop over each subject and get all auto words that have that confidence rating\n",
    "    for subject in word:\n",
    "        #x is a list containing one list of words per trial for current subject\n",
    "        x= [[]]\n",
    "        x= [[] for n in range(8)]\n",
    "        #(these are all unique lists that can be modified one at a time, before it was written so changing one changed them all)\n",
    "        \n",
    "        #for each word recalled, if conf>rate add it to x in the correct index for the trial \n",
    "        for lst in subject:\n",
    "            for recall in lst:\n",
    "                if float(conf[word.index(subject)][subject.index(lst)][lst.index(recall)]) > rate:\n",
    "                    if recall[:1] == ' ':\n",
    "                        x[subject.index(lst)].append(recall[1:])\n",
    "                    else:\n",
    "                        x[subject.index(lst)].append(recall)\n",
    "        \n",
    "        #once all words are appended to x in the right index, add x to correct list in the dictionary\n",
    "        CONF_DICT['CONF_%s' % str(rate)[2]].append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Get List of Words Auto in Man, Auto Not in Man for Each Confidence Rating </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add two lists to dictionary per confidence rating, auto in man and auto not in man\n",
    "#these are nested lists of words [subject][trial[]] \n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]] = []\n",
    "    CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]] = []\n",
    "    \n",
    "#update dictionary for each confidence rating:\n",
    "for rate in conf_rate:\n",
    "    #loop over each subject for each confidence rating\n",
    "    for subject in CONF_DICT['CONF_%s' % str(rate)[2]]:\n",
    "    \n",
    "        #in_man is a list containing one list (of words in auto also in man) per trial for current subject\n",
    "        in_man = [[]]\n",
    "        in_man = [[] for n in range(8)]\n",
    "    \n",
    "        #not_in is a list containing one list (of words in auto not also in man) per trial for current subject\n",
    "        not_in = [[]]\n",
    "        not_in = [[] for n in range(8)]\n",
    "\n",
    "        \n",
    "        for lst in subject:\n",
    "            for recall in lst: \n",
    "                #get auto in man, auto not in man for each trial\n",
    "                if recall in ALL_WORDS_MAN2[CONF_DICT['CONF_%s' % str(rate)[2]].index(subject)][subject.index(lst)]:\n",
    "                    in_man[subject.index(lst)].append(recall)\n",
    "                else:\n",
    "                    not_in[subject.index(lst)].append(recall)\n",
    "    \n",
    "        #update lists so there's one list per subject\n",
    "        CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]].append(in_man)\n",
    "        CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]].append(not_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Get Total Unique Words Between Auto and Man for Each Trial </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add one list to dictionary per confidence rating\n",
    "#these are nested lists of total unique words for each trial [subject][trial[]] \n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['UNIQUE_%s' % str(rate)[2]] = []\n",
    "\n",
    "sub_num = range(0, 28)\n",
    "trial_num = range(0, 8)\n",
    "for rate in conf_rate:  \n",
    "    for subject in sub_num:\n",
    "        #uniq is a list containing one list (of total unique words between auto and man) per trial for current subject\n",
    "        uniq = []\n",
    "        #uniq = [[] for n in range(8)]\n",
    "        \n",
    "        for trial in trial_num:\n",
    "            #get total unique words for each trial\n",
    "            auto_uniq = set(word[subject][trial])\n",
    "            man_uniq = set(ALL_WORDS_MAN2[subject][trial])\n",
    "            uniq.append(list(auto_uniq.union(man_uniq)))\n",
    "    \n",
    "        CONF_DICT['UNIQUE_%s' % str(rate)[2]].append(uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Calculate FPR and TPR for each list </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#false positive rate = # words in auto not in man / # total unique words\n",
    "#true positive rate = # words in auto that are in man / # total unique words\n",
    "\n",
    "#add two list to dictionary per confidence rating, FPR and TPR\n",
    "#these are nested lists of the proportions for each trial [subject][trial[]] \n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['FPR_%s' % str(rate)[2]] = []\n",
    "    CONF_DICT['TPR_%s' % str(rate)[2]] = []\n",
    "\n",
    "for rate in conf_rate:\n",
    "    for subject in sub_num:\n",
    "        #fpr is a list containing all FPR for that subject\n",
    "        fpr = []\n",
    "        fpr = [[] for n in range(8)]\n",
    "        \n",
    "        #tpr is a list containing all TPR for that subject\n",
    "        tpr = []\n",
    "        tpr = [[] for n in range(8)]\n",
    "        \n",
    "        for trial in trial_num:\n",
    "            #if len(CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]][subject][trial])>= 1:\n",
    "            #get FPR and TPR for each trial\n",
    "                tpr[trial] = (float(len(CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]][subject][trial])))/(float(len(CONF_DICT['UNIQUE_%s' % str(rate)[2]][subject][trial])))\n",
    "\n",
    "            #if len(CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]][subject][trial])>= 1:\n",
    "                fpr[trial] = (float(len(CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]][subject][trial])))/(float(len(CONF_DICT['UNIQUE_%s' % str(rate)[2]][subject][trial])))\n",
    "\n",
    "        \n",
    "        CONF_DICT['FPR_%s' % str(rate)[2]].append(fpr)\n",
    "        CONF_DICT['TPR_%s' % str(rate)[2]].append(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Get Average FPR and TPR for Each Subject </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these lists have one value for each subject in each confidence range (so 28*9 values total)\n",
    "FPR = []\n",
    "TPR = []\n",
    "\n",
    "#add point (1,1)\n",
    "FPR.append(1)\n",
    "TPR.append(1)\n",
    "\n",
    "#get x and y error bars\n",
    "#x error = list of standard deviations for each fpr_byrate\n",
    "x_errors = [np.float64(0.0)]\n",
    "#y error = list of standard deviations for each tpr_byrate\n",
    "y_errors = [np.float64(0.0)]\n",
    "\n",
    "for rate in conf_rate:\n",
    "    fpr_byrate = []\n",
    "    tpr_byrate = []\n",
    "    \n",
    "    #looping over all subjects for current conf rating\n",
    "    #\n",
    "    for subject in sub_num:\n",
    "        fpr_byrate.append(sum(CONF_DICT['FPR_%s' % str(rate)[2]][subject])/float(len(CONF_DICT['FPR_%s' % str(rate)[2]][subject])))\n",
    "        tpr_byrate.append(sum(CONF_DICT['TPR_%s' % str(rate)[2]][subject])/float(len(CONF_DICT['TPR_%s' % str(rate)[2]][subject])))\n",
    "    \n",
    "    FPR.append(sum(fpr_byrate)/float(len(fpr_byrate)))\n",
    "    TPR.append(sum(tpr_byrate)/float(len(tpr_byrate)))\n",
    "    \n",
    "    #add standard deviations to error barror lists\n",
    "    \n",
    "    \n",
    "    x_errors.append(np.std(fpr_byrate))\n",
    "    y_errors.append(np.std(tpr_byrate))\n",
    "    \n",
    "x_errors.append(np.float64(0.0))\n",
    "y_errors.append(np.float64(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Plot ROC Curve </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR =\n",
      "[1, 0.07349944835467005, 0.07349944835467005, 0.07315604176126346, 0.07315604176126346, 0.07172845149438747, 0.06534497262206931, 0.05892441962522955, 0.04156161822553215, 0.015898247851925708, 0]\n",
      "TPR =\n",
      "[1, 0.8808425145530548, 0.8808425145530548, 0.8808425145530548, 0.8808425145530548, 0.879133360611758, 0.8762060678998013, 0.8451709338578396, 0.6413234824508874, 0.09727023457984596, 0]\n"
     ]
    }
   ],
   "source": [
    "#add point (0,0)\n",
    "FPR.append(0)\n",
    "TPR.append(0)\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(FPR, TPR, 'ko-')\n",
    "    \n",
    "#set x and y limits, label plot\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('True Positive Rate', size = 20)\n",
    "plt.xlabel('False Positive Rate', size = 20)\n",
    "ax.set_facecolor('white')\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "#error ellipses\n",
    "ax.errorbar(FPR, TPR, xerr = x_errors, yerr = y_errors, color = 'k')\n",
    "i =0\n",
    "while i < 10:\n",
    "    ax.add_artist(Ellipse(xy = (FPR[i], TPR[i]), width = 2*x_errors[i], height = 2*y_errors[i], edgecolor = 'k', facecolor='none'))\n",
    "    i+=1\n",
    "\n",
    "# #save plot and show\n",
    "plt.savefig('/Users/contextlab/Desktop/KZroc1.pdf')\n",
    "plt.show() \n",
    "\n",
    "print 'FPR ='\n",
    "print FPR\n",
    "print 'TPR ='\n",
    "print TPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> get area under curve </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907143714072\n"
     ]
    }
   ],
   "source": [
    "print auc(FPR, TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

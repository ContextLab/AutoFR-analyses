{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import quail\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import groupby\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transcription data\n",
    "egg = pickle.load(open('../data/automatic_transcription.p', 'rb'))\n",
    "ALL_WORDS_MAN = pickle.load(open('../data/ROC_manual_transcriptions.p', 'rb'))\n",
    "\n",
    "# subject lists and confidence scores\n",
    "ROC_DATA = pickle.load(open('../data/formattedforROC.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append two missing subject ID's \n",
    "egg.meta['ids'].append(u'debugQVC5IH:debugWA2XJU')\n",
    "egg.meta['ids'].append(u'debugZANF1E:debugNSAB89')\n",
    "filenames = sorted(egg.meta['ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Organize Automatic Transcription and Confidence Ratings </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDs = range(0, 510, 17)\n",
    "\n",
    "subID=[]\n",
    "conf_list = []\n",
    "word_list = []\n",
    "\n",
    "# for each sub, get subID\n",
    "for item in ROC_DATA:\n",
    "    if ROC_DATA.index(item) in IDs:\n",
    "        subID.append(item[-23:])\n",
    "        \n",
    "    # list words and confs\n",
    "    else:\n",
    "        word_list.append(item[0][0])\n",
    "        conf_list.append(item[1][0])\n",
    "        \n",
    "# nest lists\n",
    "word = [word_list[i:i+8] for i in range(0,len(word_list), 8)]\n",
    "conf = [conf_list[i:i+8] for i in range(0,len(conf_list), 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# switch text to all caps to match manual transcriptions\n",
    "new_transcription_ROC = []\n",
    "for subject in word:\n",
    "    new_subject = []\n",
    "    for lst in subject:\n",
    "        new_lst = []\n",
    "        for word in lst:\n",
    "            new_lst.append(word.upper())\n",
    "        new_subject.append(new_lst)\n",
    "    new_transcription_ROC.append(new_subject)\n",
    "    \n",
    "word = new_transcription_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove placeholder strings \n",
    "del word[1::2]\n",
    "del conf[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Select Words By Confidence Rating </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dictionary that will have one list for every confidence rating\n",
    "CONF_DICT = {}\n",
    "conf_rate = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['CONF_%s' % str(rate)[2]] = []\n",
    "    CONF_DICT['AVG_PER_LIST_%s' % str(rate)[2]] = []\n",
    "\n",
    "for rate in conf_rate:\n",
    "    for subject in word:\n",
    "        x= [[]]\n",
    "        x= [[] for n in range(8)]\n",
    "         \n",
    "        for lst in subject:\n",
    "            for recall in lst:\n",
    "                if float(conf[word.index(subject)][subject.index(lst)][lst.index(recall)]) > rate:\n",
    "                    if recall[:1] == ' ':\n",
    "                        x[subject.index(lst)].append(recall[1:])\n",
    "                    else:\n",
    "                        x[subject.index(lst)].append(recall)\n",
    "        \n",
    "        CONF_DICT['CONF_%s' % str(rate)[2]].append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create List of Words Auto in Man, Auto Not in Man for Each Confidence Rating </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add two lists to dictionary per confidence rating, auto in man and auto not in man\n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]] = []\n",
    "    CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]] = []\n",
    "    \n",
    "for rate in conf_rate:\n",
    "    for subject in CONF_DICT['CONF_%s' % str(rate)[2]]:\n",
    "    \n",
    "        #in_man is a list containing one list (of words in auto also in man) per trial for current subject\n",
    "        in_man = [[]]\n",
    "        in_man = [[] for n in range(8)]\n",
    "    \n",
    "        #not_in is a list containing one list (of words in auto not also in man) per trial for current subject\n",
    "        not_in = [[]]\n",
    "        not_in = [[] for n in range(8)]\n",
    "\n",
    "        \n",
    "        for lst in subject:\n",
    "            for recall in lst: \n",
    "                #get auto in man, auto not in man for each trial\n",
    "                if recall in ALL_WORDS_MAN[CONF_DICT['CONF_%s' % str(rate)[2]].index(subject)][subject.index(lst)]:\n",
    "                    in_man[subject.index(lst)].append(recall)\n",
    "                else:\n",
    "                    not_in[subject.index(lst)].append(recall)\n",
    "    \n",
    "        #update lists so there's one list per subject\n",
    "        CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]].append(in_man)\n",
    "        CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]].append(not_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Total Unique Words Between Auto and Man for Each Trial </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add one list to dictionary per confidence rating\n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['UNIQUE_%s' % str(rate)[2]] = []\n",
    "\n",
    "sub_num = range(0, 28)\n",
    "trial_num = range(0, 8)\n",
    "for rate in conf_rate:  \n",
    "    for subject in sub_num:\n",
    "        uniq = []\n",
    "        \n",
    "        for trial in trial_num:\n",
    "            #get total unique words for each trial\n",
    "            auto_uniq = set(word[subject][trial])\n",
    "            man_uniq = set(ALL_WORDS_MAN[subject][trial])\n",
    "            uniq.append(list(auto_uniq.union(man_uniq)))\n",
    "    \n",
    "        CONF_DICT['UNIQUE_%s' % str(rate)[2]].append(uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Calculate FPR and TPR for Each List </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#false positive rate = # words in auto not in man / # total unique words\n",
    "#true positive rate = # words in auto that are in man / # total unique words\n",
    "\n",
    "#add two list to dictionary per confidence rating, FPR and TPR\n",
    "\n",
    "for rate in conf_rate:\n",
    "    CONF_DICT['FPR_%s' % str(rate)[2]] = []\n",
    "    CONF_DICT['TPR_%s' % str(rate)[2]] = []\n",
    "\n",
    "for rate in conf_rate:\n",
    "    for subject in sub_num:\n",
    "        #fpr is a list containing all FPR for that subject\n",
    "        fpr = []\n",
    "        fpr = [[] for n in range(8)]\n",
    "        \n",
    "        #tpr is a list containing all TPR for that subject\n",
    "        tpr = []\n",
    "        tpr = [[] for n in range(8)]\n",
    "        \n",
    "        for trial in trial_num:\n",
    "            #if len(CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]][subject][trial])>= 1:\n",
    "            #get FPR and TPR for each trial\n",
    "                tpr[trial] = (float(len(CONF_DICT['AUTO_IN_MAN_%s' % str(rate)[2]][subject][trial])))/(float(len(CONF_DICT['UNIQUE_%s' % str(rate)[2]][subject][trial])))\n",
    "\n",
    "            #if len(CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]][subject][trial])>= 1:\n",
    "                fpr[trial] = (float(len(CONF_DICT['AUTO_NOT_IN_MAN_%s' % str(rate)[2]][subject][trial])))/(float(len(CONF_DICT['UNIQUE_%s' % str(rate)[2]][subject][trial])))\n",
    "\n",
    "        \n",
    "        CONF_DICT['FPR_%s' % str(rate)[2]].append(fpr)\n",
    "        CONF_DICT['TPR_%s' % str(rate)[2]].append(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Get Average FPR and TPR for Each Subject </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#these lists have one value for each subject in each confidence range (so 28*9 values total)\n",
    "FPR = []\n",
    "TPR = []\n",
    "\n",
    "#add point (1,1)\n",
    "FPR.append(1)\n",
    "TPR.append(1)\n",
    "\n",
    "#get x and y error bars\n",
    "#x error = list of standard deviations for each fpr_byrate\n",
    "x_errors = [np.float64(0.0)]\n",
    "#y error = list of standard deviations for each tpr_byrate\n",
    "y_errors = [np.float64(0.0)]\n",
    "\n",
    "for rate in conf_rate:\n",
    "    fpr_byrate = []\n",
    "    tpr_byrate = []\n",
    "    \n",
    "    #looping over all subjects for current conf rating\n",
    "    #\n",
    "    for subject in sub_num:\n",
    "        fpr_byrate.append(sum(CONF_DICT['FPR_%s' % str(rate)[2]][subject])/float(len(CONF_DICT['FPR_%s' % str(rate)[2]][subject])))\n",
    "        tpr_byrate.append(sum(CONF_DICT['TPR_%s' % str(rate)[2]][subject])/float(len(CONF_DICT['TPR_%s' % str(rate)[2]][subject])))\n",
    "    \n",
    "    FPR.append(sum(fpr_byrate)/float(len(fpr_byrate)))\n",
    "    TPR.append(sum(tpr_byrate)/float(len(tpr_byrate)))\n",
    "    \n",
    "    x_errors.append(1.96 * np.std(fpr_byrate) / np.sqrt(29))\n",
    "    y_errors.append(1.96 * np.std(tpr_byrate) / np.sqrt(29))\n",
    "    \n",
    "x_errors.append(np.float64(0.0))\n",
    "y_errors.append(np.float64(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Plot ROC Curve </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add point (0,0)\n",
    "FPR.append(0)\n",
    "TPR.append(0)\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(FPR, TPR, 'ko-')\n",
    "    \n",
    "#set x and y limits, label plot\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('True Positive Rate', size = 20)\n",
    "plt.xlabel('False Positive Rate', size = 20)\n",
    "ax.set_facecolor('white')\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "#error ellipses\n",
    "ax.errorbar(FPR, TPR, xerr = x_errors, yerr = y_errors, color = 'k')\n",
    "\n",
    "for i in range(10):\n",
    "    ax.add_artist(Ellipse(xy = (FPR[i], TPR[i]), width = 2*x_errors[i], height = 2*y_errors[i], edgecolor = 'k', facecolor='none'))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Area Under the Curve </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9071437140720325\n"
     ]
    }
   ],
   "source": [
    "print auc(FPR, TPR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
